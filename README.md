# LLM-Guided-Reinforcement-Learning-for-Robotic-Manipulation
Description

This project combines a Large Language Model (LLM) and Reinforcement Learning (RL) to control a robotic arm for block grasping tasks in simulation. The LLM generates structured actions, and RL refines them over repeated trials.

How to Run


Steps
	•	Install dependencies (ManiSkill2, PyTorch, OpenAI API if needed).
	•	Launch the simulation and collect state data.
	•	Query the LLM for initial action plans.
	•	Apply RL fine-tuning using reward feedback.
	•	Log training results and analyze performance.

Deliverables
	•	Trained LLM + RL robotic arm policy.
	•	Grasping success evaluation under varied conditions.
	•	Final report with methods, experiments, and results.
